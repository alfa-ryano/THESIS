\chapter{Literature Review}
\label{ch:literature_review}
This work has conducted literature and existing tool review to identify problems that provide motivation for research. In this chapter present the review of this work on model persistence, model differencing and conflict detection, and the research method employed in this work.

\section{Model Persistence}
\label{sec:model_persistence}
In constructing models, it is imperative that modelling tools should support model persistence so that models being constructed can be saved at any time and reloaded for further modification. Most of these tools persist models in state-based format which means the tools capture a snapshot of a model and persist it in its entirety. Another alternative is to persists these models in change-based format. In other words, a model is persisted in its complete historical changes. Replaying these changes produces the same eventual state as the state when the model was persisted. This section compares the advantages and downsides of change-based and state-based persistence in general as well as different model persistence solutions in terms of tool support, loading, saving, and collaboration support in particular. 

\subsection{Change-based Model Persistence}
\label{sec:change_based_model_persistence}
Change-based persistence works by persisting the complete change history of models instead of persisting the snapshot -- the entire state -- of a model at a time. The concept of change-based persistence is not new and has been used in persisting changes of software, object-oriented databases, hierarchical documents, and models 
\cite{DBLP:journals/entcs/RobbesL07,DBLP:conf/sde/LippeO92,DBLP:conf/caise/IgnatN05,koegel2010emfstore}. 

The nature of change-based persistence give us two advantages. First, it contains finer-granularity information (e.g. types of changes, the order of the changes, elements that were changed, previous values, etc.) of changes which can improve the accuracy of change detection \cite{DBLP:journals/entcs/RobbesL07,DBLP:conf/sde/LippeO92,DBLP:conf/caise/IgnatN05,mens2002state}. Second, it records changes ordered manner which means that changes made to a model can be identified sequentially without having to explore and compare all elements of compared versions of models \cite{DBLP:conf/edoc/KoegelHLHD10}. The advantages to detect changes more precisely and much faster can then have positive knock-on effects on supporting (1) developers compare and merge models in collaborative modelling environments \cite{DBLP:conf/sde/LippeO92,DBLP:conf/caise/IgnatN05,koegel2010emfstore}, and (2) incremental model management \cite{jouault2010towards,DBLP:conf/ecmdafa/OgunyomiRK15, DBLP:conf/ecmdafa/RathHV12}. Moreover, changed-based persistence contains abundant information which can be exploited for analytics \cite{DBLP:journals/entcs/RobbesL07}.

Nevertheless, change-based persistence also comes with downsides, such as ever-growing model files 
\cite{DBLP:journals/entcs/RobbesL07,DBLP:conf/edoc/KoegelHLHD10} and increased model loading time \cite{mens2002state}
which increase storage and computation costs. A model that is frequently modified will increase considerably in file size 
since every change is added to the file. The increased file size (proportional to the number of persisted changes) will, 
in turn, increase the loading time of the model since all changes have to be replayed to reconstruct the model's 
eventual state. 

These downsides have to be mitigated to enable the practical adoption of change-based persistence. 
One approach to reducing the file size of change-based models is by removing changes that do not affect the eventual 
state of the model. For the increased loading time, it can be mitigated by ignoring -- i.e. not replaying -- changes 
that are cancelled out by later changes or employing change-based and state-based persistence side-by-side so that the
benefits of state-based persistence on loading time can be obtained. 

Other downsides are change-based persistence requires 
integration with existing tools -- since it is still a non-standard approach -- for its adoption \cite{koegel2010emfstore}, 
and still has limited support for standard, text-based version controls for collaborative development \cite{koegel2010emfstore}. 
These downsides can be addressed by developing a change-based persistence plugin for a specific development environment 
(e.g. Eclipse) and persisting changes in text-based format to support text-based version controls (e.g. Git, SVN).

\subsubsection{EMFStore}
\label{sec:emfstore}
The work can only identify EMFStore \cite{koegel2010emfstore} as the only implementation of change-based persistence for EMF-based models. EMFStore is a change-based model repository and version control \cite{emfstore2019what}. Instead of using SVN or Git to share your entities that have been serialized to files (e.g., XML), EMFStore has its own change-based, model-oriented mechanism for versioning. Models are shared through a server and distributed to client applications. Clients can modify the entities, offline or online, in parallel and synchronize with the server, and conflicts caused by concurrent modification are detected automatically and can be resolved interactively. The historical changes of models are kept on the server, and the historical states as well as recorded changes can be retrieved between different versions of the models. 

Every projects of EMFStore has a version history and each version represents a commit of a client. A commit sends a package of changes to the server. The package itself contains a collection of operations applied to a version that transforms it to a newer version or can be said as the deltas between the two versions. The operations can be add, delete, set, unset or move that modifies an element or feature, or they can be a composite operation, an operation that consists of many operations, e.g. refactoring that moves a method to a superclass. 

To obtain a certain version of an existing project, a client can perform checkout. This version is called the base version at the client side. The client then can perform modification to this version. Every operations applied to the version is recorded by EMF Store. Whe the client commits, these operations are put into one package and sent to the server. If the base version is still the head version of the project on the sever, the commit are accepted, and a new version is created. If they are different, it means that there is another client that already committed its changes to the server. Thus the current client has to synchronise it by updating its local project. This is the state where conflicts potentially can happen between the incoming and local changes, that is when they modify the same element or feature of a model. EMFStore performs conflict detection to identify the conflicts automatically. The mechanism of EMFStore to identify conflicts is discussed in detail in Section \ref{sec:emfstore_conflict_detection}.  

The main motivation EMFStore applies change-based approach is that calculating the differences between two versions might be expensive and is not able to recover all information since the order and logical coherence of changes is lost. Since it follows change-based approach, it does not store the state of every version. It only stores operations of each version in an ordered, logical, and coherent manner so that they can be executed and reversible to obtain the states between versions. Nevertheless, it also stores the intermediate cache states for selected versions, including the head version, to speed up the retrieval of certain versions.

The advantages of EMF Store are (1) it was designed to allow semantic versioning of models, which can support model merging and conflict detection to be more effective, and (2) efficient to identify changes particularly for large models with small modification. By default, the packages of operations are persisted in XMI files but it can also be configured to use other backends, e.g. MongoDB. EMF Store has its own mechanism for controlling versions thus limits its adopters to use common text-oriented version controls, such as Git and SVN. Its performance can also degrade as more models/users are added to a repository \cite{KolovosRMPGCLRV13}. 

\begin{table*}[h]
  \centering
  \caption{The advantages and downsides between change-based and state-based persistence.}
  \label{table:advantages_drawbacks}
  \begin{scriptsize}
    \begin{tabular}
      {|>{\centering\arraybackslash}p{1.1cm}|>{\centering\arraybackslash}p{1.1cm}|>{\centering\arraybackslash}p{5cm}|>{\centering\arraybackslash}p{5cm}|}
      \hline 
      \multicolumn{2}{|c|}{\textbf{Dimensions}}&\textbf{Change-based Approach}&\textbf{State-based Approach}\\
      \hline 
      \multicolumn{2}{|p{2.2cm}|}{\centering Advantages} &
      \begin{minipage}[t]{5cm}
        \begin{itemize}[leftmargin=9pt]
          \setlength\itemsep{2pt}
          \item[+] Faster for detecting changes \cite{DBLP:conf/edoc/KoegelHLHD10}
          \item[+] More accurate, carry semantic information \cite{DBLP:journals/entcs/RobbesL07,DBLP:conf/sde/LippeO92,DBLP:conf/caise/IgnatN05,mens2002state}  
          \item[+] Faster and more accurate for comparison and merging \cite{DBLP:conf/sde/LippeO92,DBLP:conf/caise/IgnatN05,koegel2010emfstore}
          \item[+] Information carried is useful for analytics \cite{DBLP:journals/entcs/RobbesL07}
        \end{itemize}
      \end{minipage}
      & 
      \begin{minipage}[t]{5cm}
        \raggedright
        \begin{itemize}[leftmargin=9pt]
          \setlength\itemsep{2pt}
          \item[+] Faster for loading large models \cite{DBLP:conf/models/Espinazo-PaganCM11,daniel2016neoemf,eclipse2019cdo}
          \item[+] A default standard, no need integration with existing tools \cite{koegel2010emfstore}  
        \end{itemize}
      \end{minipage}
      \\
      \hline
      \multicolumn{2}{|p{2.2cm}|}{\centering Disadvantages} & \begin{minipage}[t]{5cm}
        \raggedright
        \begin{itemize}[leftmargin=9pt]
          \setlength\itemsep{2pt}
          \item[--] Increased record size \cite{DBLP:journals/entcs/RobbesL07,DBLP:conf/edoc/KoegelHLHD10}
          \item[--] Is not efficient for replaying (loading) long records \cite{mens2002state}
          \item[--] Limited supports from standard, text-based version controls (e.g. GitHub) \cite{koegel2010emfstore} 
          \item[--] Not a standard, need integration with existing tools \cite{koegel2010emfstore} 
        \end{itemize}
      \end{minipage}
      & 
      \begin{minipage}[t]{5cm}
        \raggedright
        \begin{itemize}[leftmargin=9pt]
          \setlength\itemsep{2pt}
          \item[--] Slower for saving changes  \cite{mens2002state,daniel2016neoemf,DBLP:conf/models/Espinazo-PaganCM11}
          \item[--] Slower for comparison \cite{DBLP:conf/edoc/KoegelHLHD10}
          \item[--] Less accurate, does not carry semantic information \cite{mens2002state,DBLP:conf/edoc/KoegelHLHD10}  
        \end{itemize}
      \end{minipage}
      \\
      \hline
    \end{tabular} 
  \end{scriptsize}
\end{table*}

\subsection{State-based Model Persistence}
\label{sec:state_based_model_persistence}
Models saved in state-based persistence can be persisted in several formats, such as text files, relational databases, or NoSQL databases. This section discusses briefly the advantages and drawbacks of different solutions that persist models in these formats.

\subsubsection{EMF Default Persistence Format (XMI)}
\label{sec:xmi}
By default, modelling tools that support the 3-layer metamodelling architectures of Eclipse Modelling Framework (EMF) \cite{steinberg2008emf} employ state-based persistence to persist models in Metadata Interchange (XMI) format in text-based files. XMI is a standard issued by Object Management Group (OMG) for exchanging metadata information via Extensible Markup Language (XML) \cite{omg2018xmi}. 

Since it is the default standard, most model modelling tools support this model persistence format. In order to modify a model persisted in XMI (e.g. performing CRUD operations), the entire model has to be loaded into the memory. This can be a problem when we only want to make a small number of changes but the size of the model is very large -- it takes considerable time and memory to load the model. Also, when saving, the model has to be persisted in its entirety causing inefficiency when we only made small number of changes. Since it is a text-based file, the model can be duplicated and shared with minimum effort, e.g. through manual copy or version control systems (e.g. Git, SVN). 
However, for model comparison, text-based differencing \cite{DBLP:journals/algorithmica/Meyers86} cannot be applied accurately to XMI files since essentially they are tree documents which require different differencing approaches \cite{wang2003xdiff}.

\subsubsection{EMF Teneo}
\label{sec:emf_teneo}
EMF Teneo \cite{eclipse2017teneo} is a solution that integerates EMF with existing persistency solutions, such as Hiberbate \cite{hibernate2019hibernateorm} and EclipseLink \cite{eclipse2019eclipselink}, so that EMF models can be persisted into relational database backends. In this way, it can utilise the power of storage, caching, and querying of the database backends. It supports the automatic mapping of models to relational model schema with flexible mapping customisation. Using relational databases as its backends enables EMF Teneo to support lazy loading of models. So, when performing CRUD operations, it only loads affected elements and features into the memory as well as when saving them, which causes EMF Teneo uses less memory than XMI for large models. Thus, the perofrma  

\subsubsection{CDO}
\label{sec:cdo}
Connected Data Objects (CDO) \cite{eclipse2019cdo} is a development-time model and metamodel repository as well as a distribution and runtime persistence framework for EMF-based application systems. It supports various database-backed model persistence (e.g. relational dan NoSQL databases) and also provides facilities for collaboration, such as model differencing and conflict detection; it uses EMF Compare \cite{emfcompare2018developer} to perform the comparison \cite{cdo2019emfcompare}. However, CDO adoption necessitates the use of a separate version control system (e.g. a Git repository for code and a CDO repository for models), which introduces fragmentation and administration challenges \cite{barmpis2014evaluation}. Since it uses database backends, it also supports lazy loading of models which avoids loading and saving models in their entirety. 

\subsubsection{Morsa and NeoEMF}
\label{sec:morsa_neoemf}
Some work also has persisted EMF-based models into relational, NoSQL databases such Morsa \cite{DBLP:conf/models/Espinazo-PaganCM11} and NeoEMF \cite{daniel2016neoemf}. Morsa  persist models in documents with MongoDB backend \cite{mongodb}, while NeoEMF persists models in multi, NoSQL backends (Graph, Map, Column). However, none of these approaches provides built-in support for versioning and models are eventually stored in binary files/folders which are known to be a poor fit for text-oriented version control systems like Git and SVN. Both facilitate lazy loading which avoids loading and saving models in their entirety.

\begin{table*}[]
  \centering
  \caption{Advantages and downsides of different model persistence products.}
  \label{table:model_persistence_comparison}
\begin{scriptsize}
  \begin{tabular}{
      |>{\centering\arraybackslash}m{0.1\linewidth}
      |>{\centering\arraybackslash}m{0.4\linewidth}
      |>{\centering\arraybackslash}m{0.4\linewidth}
      |}
    \hline
    \textbf{Products} & \textbf{Advantages} & \textbf{Downsides} \\
    \hline
    XMI 
    &
    \begin{minipage}[t]{\linewidth}
      \raggedright
      \begin{itemize}[leftmargin=7pt]
        \setlength
        \item[+] default standard, widely supported
        \item[+] easy to be duplicated and shared by manual copy or text-oriented version controls
      \end{itemize}
    \end{minipage}
    & 
    \begin{minipage}[t]{\linewidth}
      \raggedright
      \begin{itemize}[leftmargin=5pt]
        \setlength
        \item[--] requires loading the entire model to modify
        \item[--] a model is saved in its entirety
        \item[--] supports text-oriented version controls, but applying text-based differencing might produce inaccurate results    
      \end{itemize}
    \end{minipage}
    \\
    \hline
    Teneo 
    & 
    \begin{minipage}[t]{\linewidth}
      \raggedright
      \begin{itemize}[leftmargin=7pt]
        \setlength
        \item[+] supports lazy loading, only load and save affected elements and features when performing CRUD operations
        \item[+] has the capabilities supported by database backends: rollback, caching, etc. 
      \end{itemize}
    \end{minipage}
    &
    \begin{minipage}[t]{\linewidth}
      \raggedright
      \begin{itemize}[leftmargin=7pt]
        \setlength
        \item[--] does not support model versioning, comparison, and merging
        \item[--] performance on loading and saving for CRUD operations depends on the database backends
        \item[--] poor-fit for text-oriented version controls since models are persisted in database
      \end{itemize}
    \end{minipage} 
    \\
    \hline
    CDO
    &
    \begin{minipage}[t]{\linewidth}
      \raggedright
      \begin{itemize}[leftmargin=7pt]
        \setlength
        \item[+] supports lazy loading, only load and save affected elements and features when performing CRUD operations
        \item[+] supports model versioning, comparison, and merging
        \item[+] has the capabilities supported by database backends: rollback, caching, etc. 
      \end{itemize}
    \end{minipage}
    &
    \begin{minipage}[t]{\linewidth}
      \raggedright
      \begin{itemize}[leftmargin=7pt]
        \setlength
        \item[--] performance on loading and saving for CRUD operations depends on the database backends
        \item[--] fragmentation and administration challenges due to separation of version controls between models and code
        \item[--] poor-fit for text-oriented version controls since models are persisted in database
      \end{itemize}
    \end{minipage} 
    \\
    \hline
    Morsa \& NeoEMF 
    & 
    \begin{minipage}[t]{\linewidth}
      \raggedright
      \begin{itemize}[leftmargin=7pt]
        \setlength
        \item[+] supports lazy loading, only load and save affected elements and features when performing CRUD operations
        \item[+] has the capabilities supported by NoSQL backends: handling big data, graph data, etc.
      \end{itemize}
    \end{minipage}
    &
    \begin{minipage}[t]{\linewidth}
      \raggedright
      \begin{itemize}[leftmargin=7pt]
        \setlength
        \item[--] does not support model versioning, comparison, and merging
        \item[--] performance on loading and saving for CRUD operations depends on the database backends
        \item[--] poor-fit for text-oriented version controls since models are persisted in database
      \end{itemize}
    \end{minipage} 
    \\
    \hline
    EMFStore
    &
    \begin{minipage}[t]{\linewidth}
      \raggedright
      \begin{itemize}[leftmargin=7pt]
        \setlength
        \item[+] supports semantic versioning of models that allows model merging and conflict detection to be more effective
      \end{itemize}
    \end{minipage}
    &
    \begin{minipage}[t]{\linewidth}
      \raggedright
      \begin{itemize}[leftmargin=7pt]
        \setlength
        \item[--] requires loading the entire model to modify
        \item[--] a model is saved in its entirety
        \item[--] persists models in the forms of files/folders and using its own mechanism for model versioning thus poor-fit for text-oriented version controls
      \end{itemize}
    \end{minipage} 
    \\
    \hline
  \end{tabular}
\end{scriptsize}
\end{table*}
  
In summary, state-based model persistence has several strong points. First, since it is the default standard of persisting models -- particularly XMI, most of the available modelling tools support this kind of persistence thus it requires minimum effort to integrate with existing tools \cite{koegel2010emfstore}. Second, it is faster in loading models since there is no need to replay all changes as in change-based persistence. Also, applying lazy loading -- elements of models are not loaded upfront -- enables faster CRUD (create, read, update, delete) operations \cite{DBLP:conf/models/Espinazo-PaganCM11,daniel2016neoemf}. 

Compared to change-based persistence, state-based persistence has several downsides. First, it is slower than change-based persistence in saving changes \cite{mens2002state}. Even thought its backends already implemented lazy loading, it still needs to undergo certain indexing mechanism to persist changes \cite{daniel2016neoemf,DBLP:conf/models/Espinazo-PaganCM11,eclipse2019cdo}. Second, state-based persistence does not have any records of recent elements that have been changed in a model. Thus, every element has to be checked for differences which can be less efficient if the comparison is performed in change-based format \cite{DBLP:conf/edoc/KoegelHLHD10}. Third, since comparison in state-based format requires deriving differences through a diffing process -- not based on actual change records, it can be less accurate than comparison in change-based persistence which is provided with more information to detect changes accurately \cite{mens2002state,DBLP:conf/edoc/KoegelHLHD10}. 

The summary of the advantages and downsides between change-based and state-based persistence and between the different model persistence solutions 
are presented in Table \ref{table:advantages_drawbacks} and \ref{table:model_persistence_comparison} respectively.

\section{Model Differencing and Conflict Detection}
\label{sec:model_differencing_and_conflict_detection}
The history of model differencing and conflict detection can be traced back to the presence of \textsf{diff} program on Unix or Unix-like platform \cite{hunt1976algorithm}. The program can perform diffing that is comparing text files ``in order to determine how or whether they differ'' \cite{diff}. Diffing basically is about finding the longest common subsequence between two or more sequences which commonly known as the Longest Common Subsequence (LCS) algorithms \cite{bergroth2000lcs}. This problem is equivalent to the Shortest Edit Script (SES) problem that is to find the smallest number of editing (add and delete) in order to make a sequence equal to another sequence \cite{DBLP:journals/algorithmica/Meyers86}. LCS or SES algorithms are commonly implemented by Version Control Systems, such as SVN \cite{svn-diff} and Git \cite{git-diff}, in their \textsf{diff} programs to identify differences between versions of files.   

Applying this diffing approach to some non-text artefacts, such as XML \cite{w3c-xml} and Ecore models \cite{steinberg2008emf}, is not straightforward since they have different characteristics to text files. For example, XML is a hierarchical document with a tree structure; one node can contains other nodes. The unique feature of XML is that its containment is  unordered whereas in text differencing order is a necessary feature. This has been addressed by Wang et al. \cite{wang2003xdiff} by exploiting key XML  structure characteristics. Identifying differences between Ecore models is even more complex since the models support multiple characteristics of features, such as attribute/reference, literal/object values, single/multiple values, containment/non-containment, etc \cite{steinberg2008emf}. 

There are several existing tools for model differencing. 
EMF Compare \cite{emfcompare2018developer} is a popular tool used to compare and merge EMF models, with generic support for different kinds of metamodels. It is an extensible framework so that it can be adapated to the specific needs of certain metamodels. EMF Compare works by performing matching between elements of models being compared and then executing differencing to identify differences between the matched elements. These matching and differencing are discussed in detail in Chapter \ref{ch:model_differencing}. It used in this study as a benchmark for comparative evaluation due to its maturity and ongoing development activity. EMF DiffMerge (EDM) \cite{eclipse2019emfdiffmerge} is similar to EMF Compare except that its abstraction is at a lower level. It means that its difference model is technical and also to support the expression of consistency rules. As consequence, EMF Compare could use EDM engine when it needs to enforce a particular consistency policy. Also, it supports model scopes which are arbitrarily-defined sets of model elements or can be said as subsets of models that can be defined by specific filters. Beyond EMF Compare and EMF DiffMerge, tools such as SiDiff \cite{Treude2007SiDiff} and DSMDiff \cite{lin2009dsmdiff} also provide language-agnostic graph-based model comparison, with some room for configuration (e.g., assigning different weights to features of types in the language). Additional expressive power -- at the cost of increased complexity and configuration effort -- is offered by dedicated comparison languages such as the Epsilon Comparison Language, which can be used to compare both homogeneous and heterogeneous models \cite{kolovos2009ecl}. All of these tools works with state-based persistence to identify differences between models.

This work does not aware of any other work that targets comparison of change-based models persisted in text files. Only EMF Store \cite{koegel2010emfstore} identified addresses change-based model conflict detection but it persists models in its own dedicated backend system. Moreover, since it is designed to identify conflicts of changes, it does not provide direct information about the differences between two versions of a model being compared. Database or dedicated-backend model persistence and version control solutions such as CDO \cite{eclipse2019cdo} and EMF Store provide model comparison capabilities between different versions of the same model but they present integration challenges when users want to use text-oriented version controls (e.g. Git, SVN) which are typically file-based and commonly used, and their performance can also degrade as more models/users are added to a repository \cite{KolovosRMPGCLRV13}. 

\subsection{The Challenges of Model Comparison}
\label{sec:the_key_challenge_of_incrementality}

The performance of identifying differences between versions of models can become crucial for large evolving models, particularly true in the latter phases of the development cycle when many small changes made to models to fine-tune them \cite{selic2003pragmatics}. This challenge has been addressed in incremental model management that changes of models are recorded and used as the basis to perform effective incremental model processing operations. In his work, Egyed \cite{egyed2011automatically} has shown that the property-access recording approach is applicable to queries such changes. More recent work has shown that variants of this approach can be used to achieve incrementality in a wide range of model processing operations, including model-to-model transformation \cite{jouault2010towards}, model-to-text transformation \cite{DBLP:conf/ecmdafa/OgunyomiRK15}, model validation, and pattern matching \cite{DBLP:conf/ecmdafa/RathHV12}---as long as changes to models can be precisely identified.  

Nonetheless, this approach works best at identifying differences between serial versions of a model; it does not work straightforwardly to identify differences between parallel -- branched -- versions. In addition, the solutions in incremental model management are coupled to their execution engines, which limits itself to work best only in single-developer environment (discussed more in Section \ref{sec:identifying_changes_in models}). In a collaborative setting, As the sizes and complexity of models grown, it is common to manages a model in multiple parallel versions. Thus, capabilities to identify differences differencing between these parallel versions and to detect conflicts between the differences are also a necessary.

Before merging two versions, model differencing and conflict detection need to be executed first in order to identify differences and conflicts between them so that the merging can be accurate. Nevertheless, performing the model differencing and conflict detection in traditional, state-based way can cause a bottleneck since it is computationally expensive and memory greedy (discussed more in Section \ref{sec:identifying_changes_in models}). Traditional, state-based model comparison requires every element of the versions being compared to be loaded into memory, matched, and then differenced \cite{emfcompare2018developer}, which is inefficient for large models that only experience a small number of changes. A novel approach is required that can compare only elements that has been modified -- not all elements -- thus can speed up model comparison.

A capability to perform efficient model differencing and conflict identification between versions is a necessary \cite{KolovosRMPGCLRV13}. It would scale up model management and collaborative modelling, which has been held back by the traditional, state-based model differencing and conflict detection.

\subsection{Identifying Changes in Models}
\label{sec:identifying_changes_in models}
There are two approaches in the literature for identifying changes in models, using notification facilities and model differencing.

\subsubsection{Notifications}
\label{sec:notifications}
In this approach, a model change tracking 
engine needs to hook into the notification facilities 
provided by the modelling tool through which the developer edits the model, 
so that the engine can directly receive notifications as soon as 
changes happen (e.g. class \textsf{giant} has been deleted, class \textsf{character} has been renamed to ``Hero''). 
This is an approach taken by the IncQuery incremental pattern matching 
framework \cite{DBLP:conf/ecmdafa/RathHV12} and the ReactiveATL incremental model-to-model 
transformation engine \cite{DBLP:conf/ecmdafa/OgunyomiRK15}. The main advantage of this 
approach is that precise and fine-grained change notifications are provided 
for free by the modelling tool (and thus do not need to be computed by the 
execution engine---which as discussed below can be expensive and inefficient). 
On the downside, this approach is a poor fit for collaborative development 
settings where modelling and automated model processing activities are 
performed by different members of the team.

\subsubsection{Model Differencing}
\label{sec:model_differencing}
  This approach eliminates the coupling between 
modelling tools and model change tracking engines. Instead of depending on 
live notifications, in this approach the developer in charge of automated model 
processing, needs to have access to a copy of the last version of the model that the model processing program (e.g. the model-to-text transformation) was 
executed upon, so that it can be compared against the current version of 
the model (e.g. using a model-differencing framework such as SiDiff or 
EMFCompare) and the delta can be computed on demand. The main advantage of 
this approach is that it works well in a collaborative development environment 
where typically developers have distinct roles and responsibilities. On the 
downside, model comparison and differencing are computationally expensive and 
memory-greedy (both versions of the model need to be loaded into memory before 
they can be compared).

In summary, tracking changes of models using notification facilities currently delivers significant performance benefits only in a single-developer environment as the approach is coupled to modelling tools. 
As a result, in collaborative development environments, 
developers need to either forgo the notification approach altogether 
or to work with model differencing, which is computationally expensive and 
memory-greedy.

\subsection{A Novel Solution to Model Change Detection}
\label{sec:a_novel_solution_to_model_change_detection}
A novel solution to model change detection should be able to deliver the advantages of both notification and model differencing approaches while eliminate their drawbacks. To realize such solution, this work comes with an idea that models can be persisted in their complete history of changes, a.k.a. change-based model persistence, as opposed to state-based model persistence that persists models in their snapshots at a time. The change-based model persistence should be text-based. Thus, information about changes of models can be preserved and can be shared across the members of a team through Version Control Systems (e.g., SVN, Git).The proposed change-based model persistence is discussed later in Chapter \ref{ch:change_based_model_persistence}. 

Moreover, change-based model persistence also can be exploited to optimise model comparison to only compares versions of a model on parts that have only been changed since their last shared common version. In other words, not every element of the versions is compared which can lead to a faster model comparison. This solution is discussed later in Chapters \ref{ch:model_differencing} and \ref{ch:conflict_detection}. 

\section{Research Method}
\label{sec:research_method}
In performing this research, this work follows the experiment process proposed by Wohlin et al. \cite{DBLP:books/daglib/0029933/Wohlin}. The experiment process consist of 5 activities: scoping, planning, operation, analysis and interpretation, and presentation and package.

\textbf{Scoping}. In the scoping activity, the hypothesis, goals, and objectives of an experiment have to be defined clearly \cite{DBLP:books/daglib/0029933/Wohlin}. Basili et al. \cite{basili1988tame} provide the following questions (scoping points) in their framework to help determining the scope of an experiment in software engineering: (1) what is studied? (object of study), (2) what is the intention? (purpose), (3) which effect is studied? (quality focus), (4) whose view? (perspective), and where is the study conducted? (context).

%This work studies change-based model persistence as an alternative method for persisting models. The study includes defining methods to load and save change-based models as well as to reduce the main drawback of the persistence -- the slow loading of change-based models. This work also investigates a method in leveraging the persistence to produce a faster model differencing and conflict detection. It is expected that change-based model persistence can support modellers/developers to improve the efficiency of their model management in the context of model-driven engineering.

\textbf{Planning}. In the planning activity, these components have to be defined in detail: context selection, hypothesis formulation, variables selection, selection of subjects, experiment design selection, instrumentation, and validity evaluation\cite{DBLP:books/daglib/0029933/Wohlin}. The context can be offline vs. online, student vs. professional, toy vs. real problems, specific vs. general. Null and alternative hypotheses have to be stated formally and the data gathered throughout the experiment should be used, using appropriate statistical tests, to reject the null hypothesis if possible. In the variables selection, we determine the independent and dependent variables to be measured. The subjects should be selected carefully that they are representative to the case experimented in order to generalise the results of the experiment. To get the desired results, experiment should be designed carefully and suitable standard design types should be selected. Experiment objects, guidelines, and measurement instruments also should be defined to ensure the experiment is executable. Lastly the validity threats should be identified and evaluated.

\textbf{Operation}. The operation activity consists of three steps: preparation, execution, and validation \cite{DBLP:books/daglib/0029933/Wohlin}. 
In the preparation, we select and inform participants and prepare all the required materials to facilitate the execution of the experiment. The experiment can be executed in a number of ways, such as in one or multiple occasions, or in one or multiyear.  While the executing, we have to make sure that the experiment is on the right track, not interrupted, and running correctly. We also have to validate the produced data if they are reasonable and collected correctly. 

\textbf{Analysis and interpretation}.
To understand the data gathered, descriptive statistics and visualization can be used. We can also remove unnecessary data and variables to facilitate analysis and interpretation. We can then perform hypothesis testing to reject or accept the experiment's hypotheses. The analysis and interpretation should explain how the data gathered contribute to the rejection or acceptance of the hypotheses. The results might be statistically insignificant, but the lessons might still worth to be learned \cite{DBLP:books/daglib/0029933/Wohlin}. 

\textbf{Presentation and package}. In this activity, experiment results should be documented and published in research papers for the dissemination of the results. The experiment also should be packaged to support other parties to replicate it \cite{DBLP:books/daglib/0029933/Wohlin}. 
